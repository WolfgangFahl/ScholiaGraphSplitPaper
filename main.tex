% Paper submitted for
% https://www.swat4ls.org/workshops/amsterdam-2026/call-for-papers/
% SWAT4LS 2026 - Wikidata in healthcare and life sciences
% Integration and Tools: Exploring how Wikidata integrates with health data systems
% Real-World Applications: Showcasing case studies of Wikidata's impact
% Challenges: Identifying challenges in using Wikidata, with proposed solutions
% https://github.com/WolfgangFahl/ScholiaGraphSplitPaper


\documentclass{ceurart}
\usepackage{comment}

\include{common}
%%
%% One can fix some overfulls
\sloppy



\begin{document}

%%
%% Rights management information.
\copyrightyear{2026}
\copyrightclause{Copyright for this paper by its authors.
  Use permitted under Creative Commons License Attribution 4.0
  International (CC BY 4.0).}

%%
%% This command is for the conference information
\conference{SWAT4HCLS 2026: The 17th International Conference on Semantic
    Web Applications and Tools for Health Care and Life Sciences,
    March 23--26, 2026, Amsterdam, The Netherlands}

%%
%% The "title" command
%\title{Scholia Wikidata Graph Split Mitigation}
\title{Scholia 2026: Compliance with SPARQL~1.1}

%%
%% The "author" command and its associated commands
\author[1]{Egon L. Willighagen}[%
    orcid=0000-0001-7542-0286,
    email=egon.willighagen@maastrichtuniversity.nl, % Add email if desired
]

\author[2,3,4]{Daniel Mietchen}[%
    orcid=0000-0001-9488-1870,
]

\author{Peter Patel-Schneider}[%
    orcid=0009-0000-7789-7459,
]

\author[5]{Konrad Linden}[%
    orcid=0009-0009-1449-5423,
]

\author[6]{Lars G. Willighagen}[%
    orcid=0000-0002-4751-4637,
]

\author[7]{Wolfgang Fahl}[%
    orcid=0000-0002-0821-6995,
]

\author[5]{Hannah Bast}[%
    orcid=0000-0003-1213-6776,
]

%% Affiliations
\address[1]{Department of Translational Genomics, NUTRIM, Maastricht University, The Netherlands}
\address[2]{FIZ Karlsruhe -- Leibniz Institute for Information Infrastructure, Karlsruhe, Germany}
\address[3]{Leibniz Institute of Freshwater Ecology and Inland Fisheries (IGB), Berlin, Germany}
\address[4]{Institute for Globally Distributed Open Research and Education (IGDORE), Jena, Germany}
\address[5]{Albert-Ludwigs-Universit√§t Freiburg, Freiburg im Breisgau, Germany}
\address[6]{Department of Ecology, Radboud Institute for Biological and Environmental Sciences,
  Radboud University, The Netherlands}
\address[7]{BITPlan GmbH, Willich, Germany}

%%
%% The abstract
\begin{abstract}
Scholia is a specialized portal that serves Wikidata content through a set of 387 precomposed SPARQL query templates.
Scholia used to query the Wikidata Query Service (WDQS), powered by the Blazegraph SPARQL engine.
This service has been facing major efficiency challenges for years, which eventually led to what is known as the
\emph{WDQS graph split}. As a consequence of this graph split, there was no longer a single service for the complete data,
but two separate services for about half of the data each. Since Scholia queries make extensive use of the complete data, a new solution was needed.
In this short demonstration paper, we describe how Scholia was migrated to the QLever SPARQL engine. As part of this process, all Blazegraph-specific constructs were removed and all queries were rewritten to be fully compliant with the SPARQL 1.1 standard. At the same time, performance was significantly improved.
\end{abstract}

%%
%% Keywords
\begin{keywords}
Scholia \sep 
Wikidata \sep
SPARQL \sep
Python
\end{keywords}

%%
%% This command processes the author and affiliation and title information
\maketitle

% \section{Story points}
%\begin{itemize}
   %  \item Introduction / background
   %  \begin{itemize}
   %      \item Wikidata exists
   %      \item Wikidata uses Blazegraph
   %      \item Blazegraph has limits
   %      \item Blazegraph alternatives are being investigated
   %      \item Scholia uses Wikidata
   %  \end{itemize}
   % \item using the split service was investigated and found to be impractical  - brings us further away from the standard, with very bad performance
   % \item Scholia migrates to standard SPARQL 1.1 for a QLever backend
   % \item ZOOM IN We demo our observations from the conversion process: non-standard SPARQL, non-standard functions, and our approaches to provide (roughly) equivalent functionality, and the continuing need to optimize queries for particular SPARQL engines
    %\item Further research: Implications for the broader transition of the backend for Wikidata/ Wikibase
%\end{itemize}


Wikidata is a crowd-curated platform providing general knowledge and references in a semantic format~\cite{Vrandecic2014}. Its official SPARQL service, the Wikidata Query Service (WDQS), has historically relied on the Blazegraph engine to evaluate queries~\cite{malyshev2018getting}. However, as Wikidata grew to over 17 billion triples, its Blazegraph backend has reached significant performance limits. This led the Wikimedia Foundation to split the query service into two parts in 2025: \emph{WDQS-main}, containing 8.6 billion triples related to general knowledge, and \emph{WDQS-scholarly}, containing 8.7 billion triples related to scholarly articles \cite{lubiana2024wdqs}.

Scholia~\cite{Nielsen_Scholia_Scientometrics_and_2017} is a specialized portal for the scientific community that 
serves
% provides access to 
Wikidata content through a set of 387 precomposed SPARQL query templates organized into over 40 profile types, called \emph{aspects}. These cover general entities such as authors, works, venues, organizations, events, and event series, as well as more special ones like taxa, diseases, chemicals, genes or proteins~\cite{Willighagen2025}. Because many Scholia queries require data from both WSDQ-main and WDQS-scholarly, the split posed a critical challenge to the continuation of the service. As an interim solution, the Wikimedia Foundation continued to provide a Blazegraph instance with the unified full graph until 
% decommissioning it on 
20 January 2026.
% 
Preparing for this change, the Scholia team investigated three primary recovery routes, 
% of which  was 
ultimately selecting the third one:
\begin{enumerate}
    \item Modifying existing queries to use SPARQL federation to communicate between the two endpoints. This was found to be impractical, as inter-service communication led to severe performance degradation and the loss of optimization opportunities \cite{lubiana2024wdqs}. 
    \item Using snapQuery middleware \cite{Fahl_SnapQuery_2025} to generalize query access across endpoints.
    \item Remove all Blazegraph-specific constructs in Scholia and make all queries fully compliant with the SPARQL 1.1 standard. This allows the use of any SPARQL 1.1 engine that is efficient enough to process queries on the complete (unsplit) Wikidata graph.
    % including QLever \cite{qlever}, MilleniumDB, and Virtuoso, not only obviating the need to switch to a split-service architecture with its inherent inefficiencies but also leveraging modern engines that are considerably faster than Blazegraph.
\end{enumerate}
% 

%Recent benchmarking of SPARQL backends \cite{patelschneider2024benchmarking} supported the decision to move toward QLever \cite{qlever}. 

% \begin{verbatim}
%     - WMF WDQS uses Blazegraph
%   - due to slowness of Blazegraph on standard SPARQL queries
%     systems that use the WDQS have Blazegraphs-specific constructs in their queries

% - WMF has split up the WDQS into two parts
%   - scholarly part
%   - main part
%   - use SPARQL federation in queries that need access to both parts

% - most SCHOLIA queries use information from both parts
%   - modifying queries to use federation is complex and time-consuming
%   - federated queries can be much slower due to inter-service communication and loss of optimization opportunities

% - decision was made to instead convert SCHOLIA to use standard SPARQL 1.1
%   - could then use any service that evaluates SPARQL 1.1 queries against the Wikidata RDF dump
%     - QLever, MilleniumDB, Virtuoso are all candidates
% \end{verbatim}

% %\section{Introduction and Background}
% The Wikidata graph split~\cite{wikidata:wdqs:graphsplit,lubiana2024wdqs} has challenged the continuation of the Scholia service. 
% Scholia~\cite{Nielsen_Scholia_Scientometrics_and_2017} is a portal for the scientific community that
% provides access to Wikidata~\cite{Vrandecic2014} curated content using a set of 387 queries organized in over 40 profile types (known as aspects). General aspects such as Author, Work, Venue, Topic, Organization, Publisher, Event and Location are covered as well as biochemical related ones such as Chemicals~\cite{Willighagen2025}, Gene/Protein, Disease, and Taxon.  Scholia accesses Wikidata by means of constructed SPARQL queries.

% The Wikimedia Foundation-provided Wikidata Query Service~\cite{wikidata:wdqs} has been using Blazegraph to evaluate queries against Wikidata.  Limitations in Blazegraph have become more and more problematic as Wikidata has grown, leading to a decision to split the service into two halves during 2025~\cite{wikidata:wdqs:graphsplit}, with one service providing access to the scholarly articles in Wikidata and the other providing access to the rest.
% %pfps these numbers seen wrong: The split led to having a wikidata-main graph with 8.6 billion triples and a wikidata-scholarly graph with 8.7 billion triples instead of the full graph having 17.1 billion triples.





% %\section{Options}
% Given a deadline of January 2026, at which point the full graph provided by the Wikimedia Foundation will not be available anymore, the Scholia project was forced to take action and pursued the following options:
% \begin{itemize}
%   \item To modify affected queries to use federation across the two split graphs 
%   \item To migrate to a different backend such as QLever \cite{qlever}
%   \item To generalize the query access using the snapQuery \cite{Fahl_SnapQuery_2025} middleware approach
% \end{itemize}




%\bigskip
%\section{Migration Process}

A fork of the original Scholia project was created~\cite{scholia:github} to collaborate on the necessary modifications, around which several hackathons were organized~\cite{wikidata:scholia:events2025}.
A decision was made to use a Wikidata query service~(\url{https://qlever.dev/api/wikidata}) powered by QLever~\cite{qlever}.
This decision was supported by benchmarking multiple SPARQL engines~\cite{patelschneider2024benchmarking}, of which QLever was fastest overall.

The bulk of the work was eliminating non-standard constructs from query templates.  The major types of these constructs were:

\def\Hitem{\smallskip\noindent\:\:$\bullet$\:}

\Hitem 
\emph{named sub-queries} to give names to sub-patterns, for multiple reuse within a query;

\Hitem 
the Blazegraph \emph{locality service}, for finding located entities within a given radius of a given point;

\Hitem 
the Blazegraph \emph{gather-scatter service}; for finding nodes reachable from a given node via $k$ hops;

\Hitem 
the \emph{MediaWiki API service} for accessing contents from the Wikipedias (e.g., via full-text search);

\Hitem 
the Wikibase \emph{label service} for finding labels for items, for a given sequence of fallback languages.

\smallskip\noindent
Most of these constructs originated as workarounds for efficiency problems with Blazegraph. For the same reason, they are also used by many other systems using the Wikidata query service. An engine like QLever, that can efficiently handle standard SPARQL constructs at the scale of Wikidata, obviates the need for such workarounds.

Specifically, named sub-queries were eliminated by substituting the named query where it was referenced.  The locality service was eliminated by unrestricted querying and filtering based on computed distances. The gather-scatter service was eliminated by using transitive closure and filters or limits.  

The hardest construct to eliminate was the Wikibase label service, because it depends on access to the entire query to determine the relevant variables and because there are many labels in Wikidata.
We solved this by using a macro that takes the variables as an argument and is expanded before the query is sent for evaluation.
The expansion uses a sequence of \emph{OPTIONAL} joins based on the HTTP \emph{Accept-Language} header sent by the browser,
with a preceding \emph{BIND} to handle potentially unbound variables that can come from previous \emph{OPTIONAL} constructs in the query.

% Some queries were initially slower under QLever than under Blazegraph.  This was unexpected because QLever is generally much faster than Blazegraph.  The queries involved \texttt{OPTIONAL} constructs, which, when run isolated,  result in large subresults.  Communications with the QLever team indicated that this was a known, current limitation in QLever, which has since been addressed. Several of the problematic queries were refactored to replace their expensive portions by using \texttt{UNION} constructs.

% \bigskip

The process took about eighteen months, with the results we had hoped for. In particular, all Scholia queries are now compliant with the SPARQL 1.1 standard, and at the same time, using QLever, most queries are now significantly faster than with the original setup using Blazegraph.

% Only very few queries still have problems in early 2026.  As several queries were problematic in Blazegraph as well, the few remaining problems with the QLever backend do not indicate a reduction in overall performance of Scholia.
% While the official Scholia service is yet to be updated to use the new QLever-based setup, 
Since the Scholia queries are complex and cover a wide range of SPARQL constructs, our effort provides strong evidence that it is realistic to make other Wikidata-based systems fully compliant with the SPARQL 1.1 standard as well, and that QLever can handle the associated efficiency challenges. In particular, this is true for the WDQS itself, which the Wikimedia Foundation plans to migrate off Blazegraph. We have not investigated whether other SPARQL-compliant engines can handle these challenges, too, and to which degree further query rewriting would be needed for them.
\medskip
%\section{Conclusion}
    
The demo at SWAT4HCLS will show query updates of various Scholia aspects to exemplify the changes made and the performance improvements achieved by using QLever. This includes a demo the Scholia page for the SWAT4HCLS event series~\cite{ScholiaSWAT4HCLS}

\begin{acknowledgments}
  The authors thank everyone who has contributed patches or bug reports to the Scholia project, particularly
  Finn Nielsen (for the original concept of Scholia), Moritz Schubotz and Lane Rasberry.
  A rich list of contributors to the project is available at \url{https://github.com/WDscholia/scholia/graphs/contributors}. The work described here was supported in part by the German Research Foundation through the find.software project \cite{gey2025find.software} (funded under grant number \href{https://gepris.dfg.de/gepris/projekt/567156310}{567156310}) and by the European Commission through the AQUANAVI initiative \cite{heger2025aquanavi} of the OSCARS project (\href{https://cordis.europa.eu/project/id/101129751}{101129751}).
\end{acknowledgments}

\section*{Declaration on Generative AI}
Some author(s) have occasionally employed Generative AI tools for the changes in the Scholia code. All code changes have been reviewed by another person.

%% References
\bibliography{references}

\end{document}